{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer, SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_files\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = load_files('C:/Users/Asus/Desktop/20_newsgroups', shuffle=True, encoding='utf-8', decode_error='replace')\n",
    "X , y = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Remove non-alphanumeric characters\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove_punctuation\n",
    "import string\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toknize data\n",
    "def tokenization(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "def remove_stopwords(text):\n",
    "   output= [i for i in text if i not in stopwords]\n",
    "   return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "def stemming(text):\n",
    "    stem_text = [porter_stemmer.stem(word) for word in text]\n",
    "    return stem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming 2\n",
    "porter_stemmer = SnowballStemmer(language = 'english')\n",
    "\n",
    "def stemming_snow(text):\n",
    "    stem_text = [porter_stemmer.stem(word) for word in text]\n",
    "    return stem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pos_tag\n",
    "def wordnet_pos(pos_tag):\n",
    "    if pos_tag.startswith('J'):\n",
    "        return nltk.corpus.wordnet.ADJ\n",
    "    elif pos_tag.startswith('V'):\n",
    "        return nltk.corpus.wordnet.VERB\n",
    "    elif pos_tag.startswith('N'):\n",
    "        return nltk.corpus.wordnet.NOUN\n",
    "    elif pos_tag.startswith('R'):\n",
    "        return nltk.corpus.wordnet.ADV\n",
    "    else:\n",
    "        return nltk.corpus.wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatizer(text):\n",
    "    tagged_text = nltk.pos_tag(text)  # Perform POS tagging\n",
    "    lemm_text = [wordnet_lemmatizer.lemmatize(word, pos=wordnet_pos(pos_tag)) for word, pos_tag in tagged_text]\n",
    "    return lemm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove_numeric\n",
    "def remove_numeric(text):\n",
    "   output= [i for i in text if not i.isnumeric()]\n",
    "   return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [preprocess_text(x) for x in X_train]\n",
    "\n",
    "X_train = [remove_punctuation(x) for x in X_train]\n",
    "\n",
    "#make all word lower case\n",
    "X_train = [x.lower() for x in X_train]\n",
    "\n",
    "X_train = [tokenization(x) for x in X_train]\n",
    "\n",
    "\n",
    "X_train = [remove_stopwords(x) for x in X_train]\n",
    "\n",
    "#X_train = [stemming(x) for x in X_train]\n",
    "\n",
    "#X_train = [stemming_snow(x) for x in X_train]\n",
    "\n",
    "\n",
    "X_train = [lemmatizer(x) for x in X_train]\n",
    "\n",
    "X_train = [remove_numeric(x) for x in X_train]\n",
    "\n",
    "#convert list to string\n",
    "X_train = [\" \".join(x) for x in X_train]\n",
    "\n",
    "\n",
    "#X_train_df = pd.DataFrame(X_train)\n",
    "#X_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [preprocess_text(x) for x in X_test]\n",
    "\n",
    "X_test = [remove_punctuation(x) for x in X_test]\n",
    "#make all word lower case\n",
    "X_test = [x.lower() for x in X_test]\n",
    "\n",
    "X_test = [tokenization(x) for x in X_test]\n",
    "\n",
    "X_test = [remove_stopwords(x) for x in X_test]\n",
    "#X_test = [stemming(x) for x in X_test]\n",
    "\n",
    "#X_test = [stemming_snow(x) for x in X_test]\n",
    "\n",
    "\n",
    "X_test = [lemmatizer(x) for x in X_test]\n",
    "X_test = [remove_numeric(x) for x in X_test]\n",
    "\n",
    "#convert list to string\n",
    "X_test = [\" \".join(x) for x in X_test]\n",
    "\n",
    "#X_test_df = pd.DataFrame(X_test)\n",
    "#X_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "nlp = vectorizer.fit_transform(X_train)\n",
    "#nlp = pd.DataFrame(vector.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the vectorizer\n",
    "nlp_test = vectorizer.transform(X_test)\n",
    "#nlp_test = pd.DataFrame(vector.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "nlp_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Classification Model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(nlp, y_train)\n",
    "KNeighborsClassifier(n_neighbors=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''prediction_on_training_data = knn.predict(nlp)\n",
    "accuracy_on_training_data = accuracy_score(y_train, prediction_on_training_data)\n",
    "f1Score = f1_score(y_train, prediction_on_training_data, average='macro')\n",
    "precision = precision_score(y_train, prediction_on_training_data, average='macro')\n",
    "recall = recall_score(y_train, prediction_on_training_data, average='macro')\n",
    "print(f\"accurecy of test data = {accuracy_on_training_data}\")\n",
    "print(f\"F1 score of test data = {f1Score}\")\n",
    "print(f\"precision of test data = {precision}\")\n",
    "print(f\"reacall of test data = {recall}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_on_test_data = knn.predict(nlp_test)\n",
    "accuracy_on_test_data = accuracy_score(y_test, prediction_on_test_data)\n",
    "f1Score = f1_score(y_test, prediction_on_test_data, average='macro')\n",
    "precision = precision_score(y_test, prediction_on_test_data, average='macro')\n",
    "recall = recall_score(y_test, prediction_on_test_data, average='macro')\n",
    "print(f\"KNN accuracy of test data = {accuracy_on_test_data}\")\n",
    "print(f\"KNN F1 score of test data = {f1Score}\")\n",
    "print(f\"KNN precision of test data = {precision}\")\n",
    "print(f\"KNN reacall of test data = {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''confusion_mat_KNN = confusion_matrix(y_test, prediction_on_test_data)\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "im = ax.imshow(confusion_mat_KNN, cmap='Blues')\n",
    "\n",
    "ax.set_xlabel('Predicted outputs', fontsize=12, color='black')\n",
    "ax.set_ylabel('True outputs', fontsize=12, color='black')\n",
    "ax.set_xticks(np.arange(len(data.target_names)))\n",
    "ax.set_yticks(np.arange(len(data.target_names)))\n",
    "ax.set_xticklabels(data.target_names, rotation=90)\n",
    "ax.set_yticklabels(data.target_names)\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(data.target_names)):\n",
    "    for j in range(len(data.target_names)):\n",
    "        text = ax.text(j, i, confusion_mat_KNN[i, j], ha=\"center\", va=\"center\", color=\"white\")\n",
    "\n",
    "ax.set_title(\"Confusion Matrix KNN\")\n",
    "fig.colorbar(im)\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "# Train and evaluate a Support Vector Machine classifier\n",
    "clf_svm = LinearSVC(C=1.0, max_iter=100000)\n",
    "clf_svm.fit(nlp, y_train)\n",
    "y_pred_svm = clf_svm.predict(nlp_test)\n",
    "\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "f1Score = f1_score(y_test, y_pred_svm, average='macro')\n",
    "precision = precision_score(y_test, y_pred_svm, average='macro')\n",
    "recall = recall_score(y_test, y_pred_svm, average='macro')\n",
    "print(f\"SVM accuracy of test data = {accuracy_svm}\")\n",
    "print(f\"SVM F1 score of test data = {f1Score}\")\n",
    "print(f\"SVM precision of test data = {precision}\")\n",
    "print(f\"SVM reacall of test data = {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "im = ax.imshow(confusion_mat_svm, cmap='Blues')\n",
    "\n",
    "ax.set_xlabel('Predicted outputs', fontsize=12, color='black')\n",
    "ax.set_ylabel('True outputs', fontsize=12, color='black')\n",
    "ax.set_xticks(np.arange(len(data.target_names)))\n",
    "ax.set_yticks(np.arange(len(data.target_names)))\n",
    "ax.set_xticklabels(data.target_names, rotation=90)\n",
    "ax.set_yticklabels(data.target_names)\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(data.target_names)):\n",
    "    for j in range(len(data.target_names)):\n",
    "        text = ax.text(j, i, confusion_mat_svm[i, j], ha=\"center\", va=\"center\", color=\"white\")\n",
    "\n",
    "ax.set_title(\"SVM Confusion Matrix\")\n",
    "fig.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(nlp, y_train)\n",
    "y_pred = clf.predict(nlp_test)\n",
    "\n",
    "accuracy_DT = accuracy_score(y_test, y_pred)\n",
    "f1Score = f1_score(y_test, y_pred, average='macro')\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "print(f\"DT accuracy of test data = {accuracy_DT}\")\n",
    "print(f\"DT F1 score of test data = {f1Score}\")\n",
    "print(f\"DT precision of test data = {precision}\")\n",
    "print(f\"DT reacall of test data = {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''confusion_mat_DT = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "im = ax.imshow(confusion_mat_svm, cmap='Blues')\n",
    "\n",
    "ax.set_xlabel('Predicted outputs', fontsize=12, color='black')\n",
    "ax.set_ylabel('True outputs', fontsize=12, color='black')\n",
    "ax.set_xticks(np.arange(len(data.target_names)))\n",
    "ax.set_yticks(np.arange(len(data.target_names)))\n",
    "ax.set_xticklabels(data.target_names, rotation=90)\n",
    "ax.set_yticklabels(data.target_names)\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(data.target_names)):\n",
    "    for j in range(len(data.target_names)):\n",
    "        text = ax.text(j, i, confusion_mat_DT[i, j], ha=\"center\", va=\"center\", color=\"white\")\n",
    "\n",
    "ax.set_title(\"DT Confusion Matrix\")\n",
    "fig.colorbar(im)\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=50)\n",
    "rf_classifier.fit(nlp, y_train)\n",
    "predictions = rf_classifier.predict(nlp_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_on_test_data = rf_classifier.predict(nlp_test)\n",
    "accuracy_on_test_data = accuracy_score(y_test, predictions)\n",
    "f1Score = f1_score(y_test, predictions, average='macro')\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "\n",
    "print(f\"Random Forest accuracy of test data = {accuracy_on_test_data}\")\n",
    "print(f\"Random Forest F1 score of test data = {f1Score}\")\n",
    "print(f\"Random Forest precision of test data = {precision}\")\n",
    "print(f\"Random Forest reacall of test data = {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''confusion_mat_RF = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "im = ax.imshow(confusion_mat_RF, cmap='Blues')\n",
    "\n",
    "ax.set_xlabel('Predicted outputs', fontsize=12, color='black')\n",
    "ax.set_ylabel('True outputs', fontsize=12, color='black')\n",
    "ax.set_xticks(np.arange(len(data.target_names)))\n",
    "ax.set_yticks(np.arange(len(data.target_names)))\n",
    "ax.set_xticklabels(data.target_names, rotation=90)\n",
    "ax.set_yticklabels(data.target_names)\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(data.target_names)):\n",
    "    for j in range(len(data.target_names)):\n",
    "        text = ax.text(j, i, confusion_mat_RF[i, j], ha=\"center\", va=\"center\", color=\"white\")\n",
    "\n",
    "ax.set_title(\"Random Forest Confusion Matrix\")\n",
    "fig.colorbar(im)\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(nlp, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''prediction_on_training_data = model.predict(nlp)\n",
    "accuracy_on_training_data = accuracy_score(y_train, prediction_on_training_data)\n",
    "f1Score = f1_score(y_train, prediction_on_training_data, average='macro')\n",
    "precision = precision_score(y_train, prediction_on_training_data, average='macro')\n",
    "recall = recall_score(y_train, prediction_on_training_data, average='macro')\n",
    "print(f\"accurecy of test data = {accuracy_on_training_data}\")\n",
    "print(f\"F1 score of test data = {f1Score}\")\n",
    "print(f\"precision of test data = {precision}\")\n",
    "print(f\"recall of test data = {recall}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_on_test_data = model.predict(nlp_test)\n",
    "accuracy_on_test_data = accuracy_score(y_test, prediction_on_test_data)\n",
    "f1Score = f1_score(y_test, prediction_on_test_data, average='macro')\n",
    "precision = precision_score(y_test, prediction_on_test_data, average='macro')\n",
    "recall = recall_score(y_test, prediction_on_test_data, average='macro')\n",
    "\n",
    "print(f\"Logistic Regression accuracy of test data = {accuracy_on_test_data}\")\n",
    "print(f\"Logistic Regression F1 score of test data = {f1Score}\")\n",
    "print(f\"Logistic Regression precision of test data = {precision}\")\n",
    "print(f\"Logistic Regression reacall of test data = {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''confusion_mat_log = confusion_matrix(y_test, prediction_on_test_data)\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 10))S\n",
    "im = ax.imshow(confusion_mat_log, cmap='Blues')\n",
    "\n",
    "ax.set_xlabel('Predicted outputs', fontsize=12, color='black')\n",
    "ax.set_ylabel('True outputs', fontsize=12, color='black')\n",
    "ax.set_xticks(np.arange(len(data.target_names)))\n",
    "ax.set_yticks(np.arange(len(data.target_names)))\n",
    "ax.set_xticklabels(data.target_names, rotation=90)\n",
    "ax.set_yticklabels(data.target_names)\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(data.target_names)):\n",
    "    for j in range(len(data.target_names)):\n",
    "        text = ax.text(j, i, confusion_mat_log[i, j], ha=\"center\", va=\"center\", color=\"white\")\n",
    "\n",
    "ax.set_title(\"Logistic Regression Confusion Matrix\")\n",
    "fig.colorbar(im)\n",
    "plt.show()'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
